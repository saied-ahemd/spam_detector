{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "spamFilteringDeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNN6YN5PnsIaws0uq9EsDGT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saied-ahemd/spam_detector/blob/main/spamFilteringDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaTjyYJ4p5Ki"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "import numpy as np\r\n",
        "import pandas as pd \r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "import pickle\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIAASZKvIcMz"
      },
      "source": [
        "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mxdpopf8cfk"
      },
      "source": [
        "# drop useless data \r\n",
        "df = df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzQOjn738gos"
      },
      "source": [
        "# rename the coulmn\r\n",
        "df.columns = ['label','data']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtpdcPHa87BE"
      },
      "source": [
        "# now let's make the ham = 0 and spam = 1\r\n",
        "df['label']= df['label'].map({'ham':0,'spam':1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7W0kb7p9N5i"
      },
      "source": [
        "# now we will get the value from the data\r\n",
        "X = df['data'].values\r\n",
        "y = df['label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHMIwuX9-MCY"
      },
      "source": [
        "# now we will spilt our data\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED69O4Of_iOK"
      },
      "source": [
        "# now let's vectorize our data\r\n",
        "# first thing we will tokinize or data\r\n",
        "token = Tokenizer()\r\n",
        "token.fit_on_texts(X_train)\r\n",
        "print(X_train[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0gYf-5nM57M"
      },
      "source": [
        "# applying sequences from the dictionary on both training and test dataset\r\n",
        "encoded_train = token.texts_to_sequences(X_train)\r\n",
        "encoded_test = token.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtunMxKtNbMR"
      },
      "source": [
        "# now let's do a padding for out text because deep learning expexet the squences to be all the same len\r\n",
        "max_len = 15\r\n",
        "padded_train = pad_sequences(encoded_train,maxlen=max_len,padding='post')\r\n",
        "padded_test = pad_sequences(encoded_test,maxlen=max_len,padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAxmI6b4Phtp"
      },
      "source": [
        "# now we can build our model\r\n",
        "vocab_size = len(token.word_index) + 1\r\n",
        "model = tf.keras.Sequential([\r\n",
        "                             tf.keras.layers.Embedding(vocab_size,28,input_length=max_len),\r\n",
        "                             tf.keras.layers.Flatten(),\r\n",
        "                             tf.keras.layers.Dense(500,activation='tanh'),\r\n",
        "                             tf.keras.layers.Dense(200,activation='relu'),\r\n",
        "                             tf.keras.layers.Dropout(0.5),\r\n",
        "                             tf.keras.layers.Dense(100,activation='relu'),\r\n",
        "                             tf.keras.layers.Dense(1,activation='sigmoid'),\r\n",
        "\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpL5KTLYkItH"
      },
      "source": [
        "# now let's compile our model\r\n",
        "model.compile(loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu3sJco1krqd"
      },
      "source": [
        "# now let's train our model\r\n",
        "model.fit(x=padded_train,y=y_train,epochs=49)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWBXx8BLlqbI",
        "outputId": "488c3f88-331a-46e1-c603-0bcf47805cef"
      },
      "source": [
        "# now let's see the eval\r\n",
        "preds = (model.predict(padded_test) > 0.5).astype(\"int32\")\r\n",
        "accuracy_score(y_test, preds)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9811659192825112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL_Oa3p9mfy8",
        "outputId": "4274a993-8b75-4df8-9e8e-5143a1f64ad2"
      },
      "source": [
        "# now let's save the model\r\n",
        "model.save('spamFilteringModel/my_model')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: spamFilteringModel/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbAz_4E7szth"
      },
      "source": [
        "# now let's save our tokanizer \r\n",
        "with open('spamFilteringModel/tokenizer.pkl', 'wb') as output:\r\n",
        "   pickle.dump(token, output, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKZbInkZttKU"
      },
      "source": [
        "# now let's load our model\r\n",
        "with open('spamFilteringModel/tokenizer.pkl', 'rb') as input:\r\n",
        "    tokenizer = pickle.load(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMquToYouDUc"
      },
      "source": [
        "# now let's create a function to process the input prediction\r\n",
        "def Pro_pre(tex):\r\n",
        "  text = token.texts_to_sequences(tex)\r\n",
        "  text = pad_sequences(text,maxlen=max_len,padding='post')\r\n",
        "  return text\r\n",
        "  "
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd2wW39Su_mT"
      },
      "source": [
        "tex = [\"Hi i'm your sister call me after work\"]\r\n",
        "t = Pro_pre(tex)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUys8GkkxiYS"
      },
      "source": [
        "# now let's call the model\r\n",
        "new_model = tf.keras.models.load_model('spamFilteringModel/my_model')\r\n"
      ],
      "execution_count": 91,
      "outputs": []
    }
  ]
}